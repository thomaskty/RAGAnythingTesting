{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae414e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ¤– RAG-ANYTHING INTERACTIVE TESTING SCRIPT\n",
      "======================================================================\n",
      "Test RAG-Anything's capabilities with various file formats!\n",
      "\n",
      "Supported formats:\n",
      "  â€¢ PDF: .pdf\n",
      "  â€¢ IMAGE: .jpg, .jpeg, .png, .bmp, .tiff, .tif, .gif, .webp\n",
      "  â€¢ OFFICE: .doc, .docx, .ppt, .pptx, .xls, .xlsx\n",
      "  â€¢ TEXT: .txt, .md\n",
      "======================================================================\n",
      "\n",
      "âœ… Valid file: research_paper.pdf (.pdf)\n",
      "2025-10-20 05:51:09,090 - INFO - ðŸš€ Initializing RAG-Anything...\n",
      "INFO: RAGAnything initialized with config:\n",
      "INFO:   Working directory: ./rag_test_storage/\n",
      "INFO:   Parser: mineru\n",
      "INFO:   Parse method: auto\n",
      "INFO:   Multimodal processing - Image: True, Table: True, Equation: True\n",
      "INFO:   Max concurrent files: 1\n",
      "2025-10-20 05:51:09,090 - INFO - âœ… RAG-Anything initialized successfully!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“„ FILE PROCESSING\n",
      "======================================================================\n",
      "ðŸ“ File: research_paper.pdf\n",
      "ðŸ“‚ Path: /home/thomaskutty/Documents/RAGAnythingTesting/research_paper.pdf\n",
      "ðŸ“Š Size: 4089.59 KB (3.99 MB)\n",
      "ðŸ”– Type: PDF (.pdf)\n",
      "======================================================================\n",
      "2025-10-20 05:51:09,090 - INFO - ðŸ”„ Processing file: research_paper.pdf\n",
      "INFO: Parser 'mineru' installation verified\n",
      "INFO: Initializing LightRAG with parameters: {'working_dir': './rag_test_storage/'}\n",
      "INFO: [_] Loaded graph from ./rag_test_storage/graph_chunk_entity_relation.graphml with 214 nodes, 292 edges\n",
      "2025-10-20 05:51:12,595 - INFO - Load (214, 3072) data\n",
      "2025-10-20 05:51:12,597 - INFO - Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': './rag_test_storage/vdb_entities.json'} 214 data\n",
      "2025-10-20 05:51:12,650 - INFO - Load (292, 3072) data\n",
      "2025-10-20 05:51:12,652 - INFO - Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': './rag_test_storage/vdb_relationships.json'} 292 data\n",
      "2025-10-20 05:51:12,655 - INFO - Load (21, 3072) data\n",
      "2025-10-20 05:51:12,655 - INFO - Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': './rag_test_storage/vdb_chunks.json'} 21 data\n",
      "INFO: [_] Process 130263 KV load full_docs with 1 records\n",
      "INFO: [_] Process 130263 KV load text_chunks with 21 records\n",
      "INFO: [_] Process 130263 KV load full_entities with 1 records\n",
      "INFO: [_] Process 130263 KV load full_relations with 1 records\n",
      "INFO: [_] Process 130263 KV load llm_response_cache with 45 records\n",
      "INFO: [_] Process 130263 doc status load doc_status with 1 records\n",
      "INFO: [_] Process 130263 KV load parse_cache with 1 records\n",
      "INFO: Multimodal processors initialized with context support\n",
      "INFO: Available processors: ['image', 'table', 'equation', 'generic']\n",
      "INFO: Context configuration: ContextConfig(context_window=1, context_mode='page', max_context_tokens=2000, include_headers=True, include_captions=True, filter_content_types=['text'])\n",
      "INFO: LightRAG, parse cache, and multimodal processors initialized\n",
      "INFO: Starting complete document processing: research_paper.pdf\n",
      "INFO: Starting document parsing: research_paper.pdf\n",
      "INFO: Using cached parsing result for: research_paper.pdf\n",
      "INFO: * Total blocks in cached content_list: 123\n",
      "INFO: Content separation complete:\n",
      "INFO:   - Text content length: 43991 characters\n",
      "INFO:   - Multimodal items count: 13\n",
      "INFO:   - Multimodal type distribution: {'equation': 5, 'image': 4, 'table': 4}\n",
      "INFO: Setting content source for context-aware multimodal processing...\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set for context extraction (format: minerU)\n",
      "INFO: Starting text content insertion into LightRAG...\n",
      "WARNING: Ignoring document ID (already exists): doc-7b8b1c8f6400bcdb16a3488c52022fb4 (research_paper.pdf)\n",
      "WARNING: No new unique documents were found.\n",
      "INFO: No documents to process\n",
      "INFO: Text content insertion complete\n",
      "INFO: Document doc-7b8b1c8f6400bcdb16a3488c52022fb4 multimodal content is already processed\n",
      "INFO: Document research_paper.pdf processing complete!\n",
      "\n",
      "======================================================================\n",
      "âœ… FILE PROCESSED SUCCESSFULLY!\n",
      "======================================================================\n",
      "ðŸ’¡ You can now ask questions about the document\n",
      "======================================================================\n",
      "\n",
      "\n",
      "â“ Question: give the statistics of experiemental datasets table as a json\n",
      "2025-10-20 05:51:12,669 - INFO - ðŸ” Querying: give the statistics of experiemental datasets table as a json\n",
      "INFO: Executing VLM enhanced query: give the statistics of experiemental datasets table as a json...\n",
      "INFO: Query nodes: JSON, Datasets, Table (top_k:40, cosine:0.2)\n",
      "INFO: Embedding func: 8 new workers initialized (Timeouts: Func: 30s, Worker: 60s, Health Check: 75s)\n",
      "INFO: Local query: 40 entites, 157 relations\n",
      "INFO: Query edges: Experimental datasets, Statistics, Data representation (top_k:40, cosine:0.2)\n",
      "INFO: Global query: 37 entites, 40 relations\n",
      "INFO: Raw search results: 58 entities, 164 relations, 0 vector chunks\n",
      "INFO: After truncation: 58 entities, 164 relations\n",
      "INFO: Selecting 18 from 18 entity-related chunks by vector similarity\n",
      "INFO: Find no additional relations-related chunks from 164 relations\n",
      "INFO: Round-robin merged chunks: 18 -> 18 (deduplicated 0)\n",
      "WARNING: Rerank is enabled but no rerank model is configured. Please set up a rerank model or set enable_rerank=False in query parameters.\n",
      "INFO: Final context: 58 entities, 164 relations, 18 chunks\n",
      "INFO: Final chunks S+F/O: E6/1 E8/2 E6/3 E8/4 E9/5 E7/6 E6/7 E7/8 E4/9 E3/10 E5/11 E1/12 E6/13 E4/14 E4/15 E2/16 E2/17 E1/18\n",
      "INFO: Found 8 image path matches in prompt\n",
      "INFO: Processed 8 images for VLM\n",
      "INFO: VLM enhanced query completed\n",
      "\n",
      "ðŸ’¡ Answer:\n",
      "Here is the statistics of experimental datasets table presented in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"datasets\": [\n",
      "    {\n",
      "      \"name\": \"DocBench\",\n",
      "      \"document_count\": 229,\n",
      "      \"average_pages\": 66,\n",
      "      \"average_tokens\": 46377,\n",
      "      \"document_types\": 5,\n",
      "      \"questions\": 1102\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"MMLongBench\",\n",
      "      \"document_count\": 135,\n",
      "      \"average_pages\": 47.5,\n",
      "      \"average_tokens\": 21214,\n",
      "      \"document_types\": 7,\n",
      "      \"questions\": 1082\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "### References\n",
      "\n",
      "* [1] research_paper.pdf\n",
      "Warning: Failed to finalize RAGAnything storages: There is no current event loop in thread 'MainThread'.\n"
     ]
    }
   ],
   "source": [
    "!python main.py --file research_paper.pdf --query \"give the statistics of experiemental datasets table as a json\" --working-dir ./rag_test_storage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41c84e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ¤– RAG-ANYTHING INTERACTIVE TESTING SCRIPT\n",
      "======================================================================\n",
      "Test RAG-Anything's capabilities with various file formats!\n",
      "\n",
      "Supported formats:\n",
      "  â€¢ PDF: .pdf\n",
      "  â€¢ IMAGE: .jpg, .jpeg, .png, .bmp, .tiff, .tif, .gif, .webp\n",
      "  â€¢ OFFICE: .doc, .docx, .ppt, .pptx, .xls, .xlsx\n",
      "  â€¢ TEXT: .txt, .md\n",
      "======================================================================\n",
      "\n",
      "âœ… Valid file: research_paper.pdf (.pdf)\n",
      "2025-10-20 05:53:51,361 - INFO - ðŸš€ Initializing RAG-Anything...\n",
      "INFO: RAGAnything initialized with config:\n",
      "INFO:   Working directory: ./rag_test_storage/\n",
      "INFO:   Parser: mineru\n",
      "INFO:   Parse method: auto\n",
      "INFO:   Multimodal processing - Image: True, Table: True, Equation: True\n",
      "INFO:   Max concurrent files: 1\n",
      "2025-10-20 05:53:51,361 - INFO - âœ… RAG-Anything initialized successfully!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“„ FILE PROCESSING\n",
      "======================================================================\n",
      "ðŸ“ File: research_paper.pdf\n",
      "ðŸ“‚ Path: /home/thomaskutty/Documents/RAGAnythingTesting/research_paper.pdf\n",
      "ðŸ“Š Size: 4089.59 KB (3.99 MB)\n",
      "ðŸ”– Type: PDF (.pdf)\n",
      "======================================================================\n",
      "2025-10-20 05:53:51,362 - INFO - ðŸ”„ Processing file: research_paper.pdf\n",
      "INFO: Parser 'mineru' installation verified\n",
      "INFO: Initializing LightRAG with parameters: {'working_dir': './rag_test_storage/'}\n",
      "INFO: [_] Loaded graph from ./rag_test_storage/graph_chunk_entity_relation.graphml with 214 nodes, 292 edges\n",
      "2025-10-20 05:53:55,063 - INFO - Load (214, 3072) data\n",
      "2025-10-20 05:53:55,064 - INFO - Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': './rag_test_storage/vdb_entities.json'} 214 data\n",
      "2025-10-20 05:53:55,103 - INFO - Load (292, 3072) data\n",
      "2025-10-20 05:53:55,105 - INFO - Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': './rag_test_storage/vdb_relationships.json'} 292 data\n",
      "2025-10-20 05:53:55,107 - INFO - Load (21, 3072) data\n",
      "2025-10-20 05:53:55,107 - INFO - Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': './rag_test_storage/vdb_chunks.json'} 21 data\n",
      "INFO: [_] Process 131301 KV load full_docs with 1 records\n",
      "INFO: [_] Process 131301 KV load text_chunks with 21 records\n",
      "INFO: [_] Process 131301 KV load full_entities with 1 records\n",
      "INFO: [_] Process 131301 KV load full_relations with 1 records\n",
      "INFO: [_] Process 131301 KV load llm_response_cache with 45 records\n",
      "INFO: [_] Process 131301 doc status load doc_status with 1 records\n",
      "INFO: [_] Process 131301 KV load parse_cache with 1 records\n",
      "INFO: Multimodal processors initialized with context support\n",
      "INFO: Available processors: ['image', 'table', 'equation', 'generic']\n",
      "INFO: Context configuration: ContextConfig(context_window=1, context_mode='page', max_context_tokens=2000, include_headers=True, include_captions=True, filter_content_types=['text'])\n",
      "INFO: LightRAG, parse cache, and multimodal processors initialized\n",
      "INFO: Starting complete document processing: research_paper.pdf\n",
      "INFO: Starting document parsing: research_paper.pdf\n",
      "INFO: Using cached parsing result for: research_paper.pdf\n",
      "INFO: * Total blocks in cached content_list: 123\n",
      "INFO: Content separation complete:\n",
      "INFO:   - Text content length: 43991 characters\n",
      "INFO:   - Multimodal items count: 13\n",
      "INFO:   - Multimodal type distribution: {'equation': 5, 'image': 4, 'table': 4}\n",
      "INFO: Setting content source for context-aware multimodal processing...\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set for context extraction (format: minerU)\n",
      "INFO: Starting text content insertion into LightRAG...\n",
      "WARNING: Ignoring document ID (already exists): doc-7b8b1c8f6400bcdb16a3488c52022fb4 (research_paper.pdf)\n",
      "WARNING: No new unique documents were found.\n",
      "INFO: No documents to process\n",
      "INFO: Text content insertion complete\n",
      "INFO: Document doc-7b8b1c8f6400bcdb16a3488c52022fb4 multimodal content is already processed\n",
      "INFO: Document research_paper.pdf processing complete!\n",
      "\n",
      "======================================================================\n",
      "âœ… FILE PROCESSED SUCCESSFULLY!\n",
      "======================================================================\n",
      "ðŸ’¡ You can now ask questions about the document\n",
      "======================================================================\n",
      "\n",
      "\n",
      "â“ Question: what are the steps mentioned in the multimodal knowledge unification diagram\n",
      "2025-10-20 05:53:55,120 - INFO - ðŸ” Querying: what are the steps mentioned in the multimodal knowledge unification diagram\n",
      "INFO: Executing VLM enhanced query: what are the steps mentioned in the multimodal knowledge unification diagram...\n",
      "INFO: LLM func: 4 new workers initialized (Timeouts: Func: 180s, Worker: 360s, Health Check: 375s)\n",
      "INFO:  == LLM cache == saving: hybrid:keywords:7844cedaec088d4c58a93bfd23c68e55\n",
      "INFO: Query nodes: Knowledge unification, Multimodal, Diagram steps (top_k:40, cosine:0.2)\n",
      "INFO: Embedding func: 8 new workers initialized (Timeouts: Func: 30s, Worker: 60s, Health Check: 75s)\n",
      "INFO: Local query: 40 entites, 139 relations\n",
      "INFO: Query edges: Multimodal knowledge unification, Steps, Diagram (top_k:40, cosine:0.2)\n",
      "INFO: Global query: 39 entites, 40 relations\n",
      "INFO: Raw search results: 58 entities, 141 relations, 0 vector chunks\n",
      "INFO: After truncation: 58 entities, 141 relations\n",
      "INFO: Selecting 20 from 20 entity-related chunks by vector similarity\n",
      "INFO: Find no additional relations-related chunks from 141 relations\n",
      "INFO: Round-robin merged chunks: 20 -> 20 (deduplicated 0)\n",
      "WARNING: Rerank is enabled but no rerank model is configured. Please set up a rerank model or set enable_rerank=False in query parameters.\n",
      "INFO: Final context: 58 entities, 141 relations, 20 chunks\n",
      "INFO: Final chunks S+F/O: E5/1 E7/2 E8/3 E4/4 E6/5 E8/6 E9/7 E3/8 E6/9 E3/10 E1/11 E6/12 E1/13 E1/14 E3/15 E1/16 E1/17 E1/18 E1/19 E2/20\n",
      "INFO: Found 7 image path matches in prompt\n",
      "INFO: Processed 7 images for VLM\n",
      "INFO: VLM enhanced query completed\n",
      "\n",
      "ðŸ’¡ Answer:\n",
      "The steps mentioned in the **Multimodal Knowledge Unification** diagram can be summarized based on the structure depicted in the diagram content. Here are the key steps involved:\n",
      "\n",
      "1. **Input Document Processing**:\n",
      "   - Various input document formats (e.g., PPT, DOC, PDF) are utilized, allowing for a diverse range of content types to be processed for knowledge extraction.\n",
      "\n",
      "2. **Structured Content List Creation**:\n",
      "   - Following the input processing, different extraction processes are applied:\n",
      "     - **Hierarchical Text Extraction**: To ensure that textual data is accurately segmented and classified.\n",
      "     - **Image Caption & Metadata Extraction**: Visual elements are analyzed, and metadata related to images is extracted to retain contextual information.\n",
      "     - **LaTeX Equation Recognition**: Mathematical expressions are identified and processed.\n",
      "     - **Table Structure Parsing**: The structure of tables is identified and organized to facilitate further analysis.\n",
      "\n",
      "3. **Multimodal Processing**:\n",
      "   - The extracted information is processed through **Multi-modal Processors**, specifically utilizing **VLM/LLM** (Visual Language Model/Large Language Model) techniques to enhance the understanding of both textual and visual inputs.\n",
      "\n",
      "4. **Dual-Graph Construction**:\n",
      "   - The system constructs both a **Text-based Knowledge Graph** and a **Cross-Modal Knowledge Graph** to represent relationships between non-textual modalities in a structured manner.\n",
      "\n",
      "5. **Knowledge Graph Utilization**:\n",
      "   - The constructed knowledge graphs serve as the foundation for knowledge retrieval, where entities, relationships, and chunk contents are integrated for subsequent steps in the retrieval process.\n",
      "\n",
      "6. **Query Processing**:\n",
      "   - The framework supports query analysis and processing, enabling users to make effective queries that leverage the constructed knowledge graphs for information retrieval.\n",
      "\n",
      "Each of these steps ensures that the rich, multimodal data is effectively curated and utilized for knowledge extraction and retrieval within the framework.\n",
      "\n",
      "### References\n",
      "\n",
      "- [1] research_paper.pdf\n",
      "Warning: Failed to finalize RAGAnything storages: There is no current event loop in thread 'MainThread'.\n"
     ]
    }
   ],
   "source": [
    "!python main.py --file research_paper.pdf --query \"what are the steps mentioned in the multimodal knowledge unification diagram\" --working-dir ./rag_test_storage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ee4373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ðŸ¤– RAG-ANYTHING INTERACTIVE TESTING SCRIPT\n",
      "======================================================================\n",
      "Test RAG-Anything's capabilities with various file formats!\n",
      "\n",
      "Supported formats:\n",
      "  â€¢ PDF: .pdf\n",
      "  â€¢ IMAGE: .jpg, .jpeg, .png, .bmp, .tiff, .tif, .gif, .webp\n",
      "  â€¢ OFFICE: .doc, .docx, .ppt, .pptx, .xls, .xlsx\n",
      "  â€¢ TEXT: .txt, .md\n",
      "======================================================================\n",
      "\n",
      "âœ… Valid file: research_paper.pdf (.pdf)\n",
      "2025-10-20 05:57:43,327 - INFO - ðŸš€ Initializing RAG-Anything...\n",
      "INFO: RAGAnything initialized with config:\n",
      "INFO:   Working directory: ./rag_test_storage/\n",
      "INFO:   Parser: mineru\n",
      "INFO:   Parse method: auto\n",
      "INFO:   Multimodal processing - Image: True, Table: True, Equation: True\n",
      "INFO:   Max concurrent files: 1\n",
      "2025-10-20 05:57:43,328 - INFO - âœ… RAG-Anything initialized successfully!\n",
      "\n",
      "======================================================================\n",
      "ðŸ“„ FILE PROCESSING\n",
      "======================================================================\n",
      "ðŸ“ File: research_paper.pdf\n",
      "ðŸ“‚ Path: /home/thomaskutty/Documents/RAGAnythingTesting/research_paper.pdf\n",
      "ðŸ“Š Size: 4089.59 KB (3.99 MB)\n",
      "ðŸ”– Type: PDF (.pdf)\n",
      "======================================================================\n",
      "2025-10-20 05:57:43,328 - INFO - ðŸ”„ Processing file: research_paper.pdf\n",
      "INFO: Parser 'mineru' installation verified\n",
      "INFO: Initializing LightRAG with parameters: {'working_dir': './rag_test_storage/'}\n",
      "INFO: [_] Loaded graph from ./rag_test_storage/graph_chunk_entity_relation.graphml with 214 nodes, 292 edges\n",
      "2025-10-20 05:57:46,366 - INFO - Load (214, 3072) data\n",
      "2025-10-20 05:57:46,367 - INFO - Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': './rag_test_storage/vdb_entities.json'} 214 data\n",
      "2025-10-20 05:57:46,403 - INFO - Load (292, 3072) data\n",
      "2025-10-20 05:57:46,405 - INFO - Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': './rag_test_storage/vdb_relationships.json'} 292 data\n",
      "2025-10-20 05:57:46,407 - INFO - Load (21, 3072) data\n",
      "2025-10-20 05:57:46,407 - INFO - Init {'embedding_dim': 3072, 'metric': 'cosine', 'storage_file': './rag_test_storage/vdb_chunks.json'} 21 data\n",
      "INFO: [_] Process 132871 KV load full_docs with 1 records\n",
      "INFO: [_] Process 132871 KV load text_chunks with 21 records\n",
      "INFO: [_] Process 132871 KV load full_entities with 1 records\n",
      "INFO: [_] Process 132871 KV load full_relations with 1 records\n",
      "INFO: [_] Process 132871 KV load llm_response_cache with 46 records\n",
      "INFO: [_] Process 132871 doc status load doc_status with 1 records\n",
      "INFO: [_] Process 132871 KV load parse_cache with 1 records\n",
      "INFO: Multimodal processors initialized with context support\n",
      "INFO: Available processors: ['image', 'table', 'equation', 'generic']\n",
      "INFO: Context configuration: ContextConfig(context_window=1, context_mode='page', max_context_tokens=2000, include_headers=True, include_captions=True, filter_content_types=['text'])\n",
      "INFO: LightRAG, parse cache, and multimodal processors initialized\n",
      "INFO: Starting complete document processing: research_paper.pdf\n",
      "INFO: Starting document parsing: research_paper.pdf\n",
      "INFO: Using cached parsing result for: research_paper.pdf\n",
      "INFO: * Total blocks in cached content_list: 123\n",
      "INFO: Content separation complete:\n",
      "INFO:   - Text content length: 43991 characters\n",
      "INFO:   - Multimodal items count: 13\n",
      "INFO:   - Multimodal type distribution: {'equation': 5, 'image': 4, 'table': 4}\n",
      "INFO: Setting content source for context-aware multimodal processing...\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set with format: minerU\n",
      "INFO: Content source set for context extraction (format: minerU)\n",
      "INFO: Starting text content insertion into LightRAG...\n",
      "WARNING: Ignoring document ID (already exists): doc-7b8b1c8f6400bcdb16a3488c52022fb4 (research_paper.pdf)\n",
      "WARNING: No new unique documents were found.\n",
      "INFO: No documents to process\n",
      "INFO: Text content insertion complete\n",
      "INFO: Document doc-7b8b1c8f6400bcdb16a3488c52022fb4 multimodal content is already processed\n",
      "INFO: Document research_paper.pdf processing complete!\n",
      "\n",
      "======================================================================\n",
      "âœ… FILE PROCESSED SUCCESSFULLY!\n",
      "======================================================================\n",
      "ðŸ’¡ You can now ask questions about the document\n",
      "======================================================================\n",
      "\n",
      "\n",
      "â“ Question: overall accuracy of gpt4omini in mmlongbench\n",
      "2025-10-20 05:57:46,416 - INFO - ðŸ” Querying: overall accuracy of gpt4omini in mmlongbench\n",
      "INFO: Executing VLM enhanced query: overall accuracy of gpt4omini in mmlongbench...\n",
      "INFO: LLM func: 4 new workers initialized (Timeouts: Func: 180s, Worker: 360s, Health Check: 375s)\n",
      "INFO:  == LLM cache == saving: hybrid:keywords:8ab98ed0b9b60a5d3517b69a3082edd5\n",
      "INFO: Query nodes: Performance metrics, Benchmarking, Natural language processing, Model evaluation (top_k:40, cosine:0.2)\n",
      "INFO: Embedding func: 8 new workers initialized (Timeouts: Func: 30s, Worker: 60s, Health Check: 75s)\n",
      "INFO: Local query: 40 entites, 107 relations\n",
      "INFO: Query edges: Overall accuracy, GPT-4Omini, MMLongBench (top_k:40, cosine:0.2)\n",
      "INFO: Global query: 32 entites, 40 relations\n",
      "INFO: Raw search results: 53 entities, 111 relations, 0 vector chunks\n",
      "INFO: After truncation: 53 entities, 111 relations\n",
      "INFO: Selecting 13 from 13 entity-related chunks by vector similarity\n",
      "INFO: Find no additional relations-related chunks from 111 relations\n",
      "INFO: Round-robin merged chunks: 13 -> 13 (deduplicated 0)\n",
      "WARNING: Rerank is enabled but no rerank model is configured. Please set up a rerank model or set enable_rerank=False in query parameters.\n",
      "INFO: Final context: 53 entities, 111 relations, 13 chunks\n",
      "INFO: Final chunks S+F/O: E15/1 E12/2 E12/3 E6/4 E4/5 E9/6 E6/7 E4/8 E1/9 E2/10 E5/11 E2/12 E1/13\n",
      "INFO: Found 6 image path matches in prompt\n",
      "INFO: Processed 6 images for VLM\n",
      "INFO: VLM enhanced query completed\n",
      "\n",
      "ðŸ’¡ Answer:\n",
      "The overall accuracy of the GPT-4o-mini model in the MMLongBench evaluation is displayed in Table 3. Specifically, GPT-4o-mini achieves an overall accuracy of **42.8%** across various domains evaluated within the MMLongBench framework.\n",
      "\n",
      "This evaluation includes multiple categories, such as Research Reports/Introductions, Tutorials/Workshops, Academic Papers, Guidebooks, Brochures, Administration/Industry Files, and Financial Reports. Within these domains, the accuracy percentages for GPT-4o-mini vary, but the overall score reflects its performance across the entire MMLongBench benchmarking process.\n",
      "\n",
      "### References\n",
      "\n",
      "* [1] research_paper.pdf\n",
      "Warning: Failed to finalize RAGAnything storages: There is no current event loop in thread 'MainThread'.\n"
     ]
    }
   ],
   "source": [
    "!python main.py --file research_paper.pdf --query \"overall accuracy of gpt4omini in mmlongbench\" --working-dir ./rag_test_storage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391852e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
